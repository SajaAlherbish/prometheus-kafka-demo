# Prometheus â†’ Telegraf â†’ Kafka Pipeline

This project simulates a **metrics pipeline** where custom Python metrics are exposed to **Prometheus**, processed by **Telegraf**, forwarded into **Kafka**, and also stored in **InfluxDB** using Prometheus `remote_write`.  
With **Chronograf**, you can visualize and explore the metrics in a user-friendly UI.


## ğŸš€ Architecture

<img width="1180" height="462" alt="image" src="https://github.com/user-attachments/assets/d801a12f-929d-46ce-8a33-6638699612cd" />


### Flow Description

 - Python Exporter â€” Generates synthetic metrics and exposes them on an HTTP endpoint

 - Prometheus â€” Scrapes the metrics from the exporter using the config in prometheus.yml

 - Telegraf â€” Collects metrics from Prometheus and forwards them to Kafka

 - Kafka â€” Receives the metrics stream for analytics, monitoring, or logging

 - InfluxDB â€” Stores Prometheus metrics using the remote_write feature

 - Chronograf â€” Visualizes and queries metrics stored in InfluxDB
   

## ğŸ“‚ Project Structure

```
prometheus-kafka/
â”œâ”€â”€ docker-compose.yml         # Orchestrates all services
â”œâ”€â”€ prometheus.yml             # Prometheus scraping configuration
â”œâ”€â”€ telegraf.conf              # Telegraf configuration (forwarding metrics)
â”œâ”€â”€ telegraf-python.Dockerfile # Custom Telegraf build
â”œâ”€â”€ requirements.txt           # Root Python dependencies
â””â”€â”€ exporter/
    â”œâ”€â”€ metrics_exporter.py    # Custom Python metrics exporter
    â”œâ”€â”€ Dockerfile             # Dockerfile for the exporter
    â””â”€â”€ requirements.txt       # Exporter dependencies
```

## ğŸ› ï¸ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/USERNAME/prometheus-kafka-demo.git
cd prometheus-kafka-demo
```

### 2. Start the Services

```bash
docker-compose up --build -d
```

### 3. Access the Components

- **Prometheus UI** â†’ http://localhost:9090
- **Exporter Metrics** â†’ http://localhost:8000/metrics
- **Prometheus Targets** â†’ Navigate to Status â†’ Targets in the Prometheus UI
- **Chronograf UI** â†’ http://localhost:8888

### 4. Consume Metrics from Kafka

To verify that metrics are flowing into Kafka:

```bash
# Open a shell inside the Kafka container
docker exec -it kafka /bin/bash

# Inside the Kafka container, run the consumer
kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic prometheus-metrics \
  --from-beginning
```

You should see metrics being streamed in real time from Prometheus â†’ Telegraf â†’ Kafka.

## ğŸ“Š Metrics Exposed

The exporter provides the following metrics:

### ğŸ”¹ Throughput Metrics

- `avgThroughputIn` â€” Average inbound throughput
- `avgThroughputOut` â€” Average outbound throughput
- `lastThroughputIn` â€” Last recorded inbound throughput
- `lastThroughputOut` â€” Last recorded outbound throughput
- `maxThroughputIn` â€” Maximum inbound throughput observed
- `maxThroughputOut` â€” Maximum outbound throughput observed

### ğŸ”¹ Data Counters

- `totalBytesIn` â€” Total bytes received
- `totalBytesOut` â€” Total bytes sent

### ğŸ”¹ Connection Metrics

- `totalConnections` â€” Current total active connections
- `maxTotalConnections` â€” Maximum allowed connections
- `connections_file` â€” File-based stream connections
- `connections_hlsv3` â€” HLSv3 stream connections
- `connections_llhls` â€” Low-latency HLS connections
- `connections_ovt` â€” OVT stream connections
- `connections_push` â€” Push protocol connections
- `connections_srt` â€” SRT stream connections
- `connections_thumbnail` â€” Thumbnail stream connections
- `connections_webrtc` â€” WebRTC connections
